<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Forecasting Economic Growth Using Business News Data</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="./bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="./css/style.css" rel="stylesheet">
    <style>
        body {
        padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
        }
    </style>
    <link href="./bootstrap/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="../bootstrap/js/html5shiv.js"></script>
    <![endif]-->

    <!-- Fav icons -->
    <link rel="shortcut icon" href="./images/harvard.png">

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!--<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="./bootstrap/js/bootstrap.min.js"></script>
</head>

<body>


<div class="navbar navbar-inverse navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="brand" href="#">CS109a-Project</a>
            <div class="nav-collapse collapse">
                <ul class="nav">
                    <li class="active"><a href="#home">Home</a></li>
                    <li><a href="#ipynb">Analysis</a></li>
                    <li><a href="#references">References</a></li>
                    <li><a href="#about">About us</a></li>
                </ul>
                <a id="forkme_banner" href="https://github.com/dkmalav/cs109a-project">View on GitHub</a>
            </div><!--/.nav-collapse -->
        </div>
    </div>
</div>

<div id="home" class="container content">
    <!--<div class="hero-unit" style="background: url('http://nite-lite.org/wp-content/uploads/2016/06/business-news.jpg')">-->
    <div class="hero-unit" style="background-color: #2ba6cb; text-align: center;">
        <h1><font color="white">Forecasting Economic Growth Using Business News</font></h1>
        <p><font color="black">Dinesh Malav, Maja Campara, Naveen Sinha, Udaykiran Tadiparty</font></p>
    </div>
    <div>
        <h3>Introduction</h3>
        <hr/>
        <div>
            Business news sentiment can be conjectured to both reflect how the economy is doing, as well as
            influencing the spending of consumers and investors who read it. It is likely, therefore, there is
            predictive value in the sentiment that is contained in business news. This project will collect
            business news over a certain time span, perform sentiment analysis on it, and forecast economic
            growth (GDP). These forecasts are relevant for e.g. investors making investment decisions, or for
            policy makers who wish to meet a certain economic policy objective.
        </div>

        <h3>Objective</h3>
        <hr/>
        <div>
            Predict GDP (economic growth) from the sentiment that is contained in
            <a href="http://www.nytimes.com/">The New York Times</a> business news,
            perhaps supplemented with traditional economic indicators.
        </div>

        <h3>Data Collection</h3>
        <hr/>

        <h4>Economic Data Collection</h4>
        <div>
            To analyze and assess GDP data for the US, quarterly and yearly data were downloaded from the
            <a href="http://www.bea.gov/">U.S. Bureau of Economic Analysis (BEA)</a> dating back to 1947. This data
            contains GDP value in current dollars and chained 2009 dollars in billions. The US GDP data are
            released quarterly. The GDP value is mostly increasing over time except when there is a recession, to measure
            the actual change in the GDP we consider GDP rate of change in chained 2009 dollar value. Following two charts
            show change in GDP and rate of change in GDP value compared to previous quarter. It was observed that rate
            of change does not follow any particular pattern. According to our hypothesis the news sentiment for the
            same period should directly correlate with rate of change in GDP.
        </div>

        <div class="row">
            <div class="span6" style="text-align: center;">
                <img src="./images/usgdp.png">
            </div>
            <div class="span6" style="text-align: center;">
                <img src="./images/usgdp_rate.png">
            </div>
        </div>

        <h4>Business News Collection</h4>
        <div>
            In order to establish correlation between business news and economic growth, it is important to identify
            relevant news and classify them into 'good' or 'bad' news category. This section describes how the business
            news was collected and converted into feature for training machine learning models.

            The New York Times (NYT) provides an Article Search API to fetch data related to news articles. This API
            does not return full text of articles, but it returns a number of helpful metadata such as subject
            terms, abstract, lead paragraph, and date, as well as URLs, which one could conceivably use to scrape the
            full text of articles. For this project only lead paragraph for business articles for specified time period
            were collected. In order to request data from NYT an API key must be requested from
            <a href="http://developer.nytimes.com/">NYT Developers Network</a>. The article search API is limited
            to 1K calls per day, and 5 calls per second. These limits impose challenge for collecting as much data
            as possible for a day and time period. Based on the limited time for the project, the data collection was
            limited to two API calls or 20 article per day. This allowed to request 500 days worth of data per day.
            A python wrapper was developed around NYT Article Search API to get articles for a given start and end date.
            The reqested lead paragraph data are then store in a file with file name reflecting the day in the
            format YYYYMMDD.txt

        </div>
        <div>
            Following code wraps NYT Api in a python class. This code was used to periodically run every day to make
            number of allowed calls to NYT Api. Since API allows only 1000 call per day, the news article collection
            was limited to 2 pages each day or 20 articles for a day.
        </div>
        <pre class="pre-scrollable">
import os
import requests
import time
import json
from datetime import datetime, timedelta


class NYTArticlesApi(object):
    def __init__(self, api_key):
        self.api_key = api_key
        self.url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'

    def get_articles(self, start_date, end_date, page):
        start_date_str = start_date.strftime('%Y%m%d')
        end_date_str = end_date.strftime('%Y%m%d')

        params = {
            'api-key': self.api_key,
            'fq': "section_name:Business",
            'begin_date': start_date_str,
            'end_date': end_date_str,
            'fl': "lead_paragraph",
            'sort': "newest",
            'page': page
        }
        r = requests.get(self.url, params=params)

        if r.status_code == 200:
            response = json.loads(r.text)
            docs = response['response']['docs']
            return [item['lead_paragraph'] for item in docs]

        print "Error: api response: ", r.status_code, "Message :", r.text
        return None

    def fetch_articles(self, start_date, end_date, data_dir):
        cur_date = start_date
        while cur_date >= end_date:
            print 'Processing ', cur_date, '...'
            articles = []
            # get 2 pages for each day, i.e. 20 articles
            for page in range(2):
                articles_page = self.get_articles(cur_date, cur_date, page)
                if articles_page:
                    articles += articles_page
                else:
                    print "No data for page {0}.".format(page)
                    time.sleep(1)
                    break
                time.sleep(1)

            if len(articles) > 0:
                file_name = data_dir + cur_date.strftime('%Y%m%d') + '.txt'
                with open(file_name, 'wb',) as f:
                    for text in articles:
                        if text:
                            f.write(text.encode('utf-8').strip() + '\n')

            else:
                print "Error fetching articles for {0}.".format(cur_date)
                file_name = data_dir + "last_date.txt"
                with open(file_name, 'wb',) as f:
                    f.write(cur_date.strftime('%Y%m%d'))
                return

            cur_date -= timedelta(days=1)
        </pre>

        <div>
            On an average around 7000 articles were collect for a year. It was discovered by reading some articles
            that not all the articles were US news, these articles can be filtered by checking if any of the country
            name other than US was present. It would also allow for testing if rest of the world news also affects the
            economic grown in US.
        </div>

        <div>
            The articles for a each day were saved to individual file but it was difficult to manage data in files. A
            wrapper class was developed for saving data to SQLite database for easier management and quering data as
            required.
        </div>

        <pre class="pre-scrollable">
# Class to load data in a SQLite database
class SqliteDB(object):
    def __init__(self, db_file):
        self.db_file = db_file
        self.con = sqlite.connect(db_file)
        self.cur = self.con.cursor()

    def close_connection(self):
        self.con.close()

    def create_articles_table(self):
        self.cur.execute("CREATE TABLE Articles(Day DATE, ArticleId INT, Article TEXT, UNIQUE(Day, ArticleId) ON CONFLICT REPLACE)")

    def insert_articles(self, file_name, cur_date):
        with open(file_name, 'rb',) as f:
            articles = f.readlines()

        for i, article in enumerate(articles):
            article = article.replace('\'', '')
            self.cur.execute("INSERT INTO Articles VALUES('{0}','{1}','{2}')".format(cur_date, i, article))


    def insert_data(self, data_dir, start_date, end_date):
        print start_date, end_date
        cur_date = start_date
        while cur_date >= end_date:
            cur_date_str = cur_date.strftime('%Y-%m-%d')
            print cur_date_str
            file_name = data_dir + cur_date.strftime('%Y%m%d') + '.txt'
            # print file_name
            if os.path.exists(file_name):
                self.insert_articles(file_name, cur_date_str)

            cur_date -= timedelta(days=1)

        self.con.commit()

    def query_data(self, query):
        df = pd.read_sql(query, self.con)
        return df;
        </pre>

        <div>
            Once data are loaded to database it can be queried to easily group data for any time period.
        </div>
        <pre class="pre-scrollable">
ddb = SqliteDB('../data/articles.sqlite')
query = "SELECT strftime(\"%Y\", Day) as 'year', count(*) as 'count' FROM Articles group by strftime(\"%Y\", Day)"
df = db.query_data(query)

f, axs = plt.subplots(1,1,figsize=(15,5))
plt.title('Number of articles vs year')
plt.ylabel('Number of articles')
df.plot(kind='bar', x='year', y='count', ax=axs, alpha=0.5)
plt.show()
        </pre>

        <div class="row">
            <div class="span12" style="text-align: center;">
                <img src="./images/article_count.png">
            </div>
        </div>

        <h3>Data Exploration</h3>
        <hr/>
        <div>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed consectetur mauris vel pellentesque iaculis.
            Quisque sed ante consequat, vehicula nisi id, elementum felis. Aliquam eget euismod sem, vel venenatis nisl.
            Maecenas id neque eget est dignissim tincidunt. In lorem ex, suscipit quis ipsum at, consequat congue ex.
            Nullam ac nunc quam. Maecenas semper finibus dignissim. Mauris imperdiet vel nulla et rhoncus.
            Mauris malesuada fringilla nibh. Ut faucibus tristique dui pellentesque porta. Morbi sem ex, ornare mattis
            dui id, convallis rutrum dolor.
        </div>

        <h3>Data Modeling and Analysis</h3>
        <hr/>
        <div>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed consectetur mauris vel pellentesque iaculis.
            Quisque sed ante consequat, vehicula nisi id, elementum felis. Aliquam eget euismod sem, vel venenatis nisl.
            Maecenas id neque eget est dignissim tincidunt. In lorem ex, suscipit quis ipsum at, consequat congue ex.
            Nullam ac nunc quam. Maecenas semper finibus dignissim. Mauris imperdiet vel nulla et rhoncus.
            Mauris malesuada fringilla nibh. Ut faucibus tristique dui pellentesque porta. Morbi sem ex, ornare mattis
            dui id, convallis rutrum dolor.
        </div>

        <h3>Prediction</h3>
        <hr/>
        <div>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed consectetur mauris vel pellentesque iaculis.
            Quisque sed ante consequat, vehicula nisi id, elementum felis. Aliquam eget euismod sem, vel venenatis nisl.
            Maecenas id neque eget est dignissim tincidunt. In lorem ex, suscipit quis ipsum at, consequat congue ex.
            Nullam ac nunc quam. Maecenas semper finibus dignissim. Mauris imperdiet vel nulla et rhoncus.
            Mauris malesuada fringilla nibh. Ut faucibus tristique dui pellentesque porta. Morbi sem ex, ornare mattis
            dui id, convallis rutrum dolor.
        </div>

        <h3>Conclusion</h3>
        <hr/>
        <div>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed consectetur mauris vel pellentesque iaculis.
            Quisque sed ante consequat, vehicula nisi id, elementum felis. Aliquam eget euismod sem, vel venenatis nisl.
            Maecenas id neque eget est dignissim tincidunt. In lorem ex, suscipit quis ipsum at, consequat congue ex.
            Nullam ac nunc quam. Maecenas semper finibus dignissim. Mauris imperdiet vel nulla et rhoncus.
            Mauris malesuada fringilla nibh. Ut faucibus tristique dui pellentesque porta. Morbi sem ex, ornare mattis
            dui id, convallis rutrum dolor.
        </div>


    </div>

</div> <!-- /container -->

<div class="container hidden content" id="references">
    <h3>References</h3>
    <hr/>
    <div>
        <ol class="list-group">
            <li class="list-group-item">
                Zhang, D., Simoff, S.J. and Debenham, J., 2005, December. Exchange rate modelling using news
                articles and economic data. In Australasian Joint Conference on Artificial Intelligence
                (pp. 467-476). Springer Berlin Heidelberg.
            </li>
            <li class="list-group-item">
                Li, G, Liu, F., 2013, Sentiment analysis based on clustering: a framework in improving accuracy
                and recognizing neutral opinions. Applied Intelligence 40: pp.441–452. Doi: 10.1007/s10489-013-0463-3
            </li>
            <li class="list-group-item">
                Esuli, A. , Sebastiani, F., 2006, SENTIWORDNET: A Publicly Available Lexical Resource for Opinion
                Mining. 5th Conference on Language Resources and Evaluation (LREC’06)
            </li>
            <li>
                "US Department of Commerce, BEA", Bureau of Economic Analysis,
                http://www.bea.gov/national/index.htm#gdp,, 05 Nov 2016
            </li>
            <li>
                "Economic Indicator", Wikipedia, https://en.wikipedia.org/wiki/Economic_indicator, 31 July 2016
            </li>
        </ol>
    </div>
</div>  <!-- /container -->

<div class="container hidden content" id="about">
    <div class="row" style="margin-top:20px;">
        <div class="span2"><img src="http://a.espncdn.com/combiner/i?img=/i/headshots/nfl/players/full/2330.png&w=350&h=254"></div>
        <h3 class="span8">Dinesh Malav</h3>
    </div>
    <hr/>
    <div class="row" style="margin-top:20px;">
        <div class="span2"><img src="http://a.espncdn.com/combiner/i?img=/i/headshots/nfl/players/full/2330.png&w=350&h=254"></div>
        <h3 class="span8">Maja Campara</h3>
    </div>
    <hr/>
    <div class="row" style="margin-top:20px;">
        <div class="span2"><img src="http://a.espncdn.com/combiner/i?img=/i/headshots/nfl/players/full/2330.png&w=350&h=254"></div>
        <h3 class="span8">Naveen Sinha</h3>
    </div>
    <hr/>
    <div class="row" style="margin-top:20px;">
        <div class="span2"><img src="http://a.espncdn.com/combiner/i?img=/i/headshots/nfl/players/full/2330.png&w=350&h=254"></div>
        <h3 class="span8">Udaykiran Tadiparty</h3>
    </div>
    <hr/>
</div>  <!-- /container -->

<div class="hidden content" id="ipynb">
    <object type="text/html" data="ipynb.html" width="100%" height="800px">
    </object>
</div>  <!-- /container -->


<script>
$(".nav a").on('click',function(e) {
    // make clicked tab active
    $(".nav").find(".active").removeClass("active");
    $(this).parent().addClass("active");

    // remove hidden class from current tab content, hide everything and show this tab contents
    $($(this).attr('href')).removeClass("hidden");
    $(".content").hide();
    $($(this).attr('href')).show();
});
</script>
</body>
</html>
